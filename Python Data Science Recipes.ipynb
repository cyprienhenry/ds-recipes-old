{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving time in Python for common Data Science tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this workbook is to act as a quick reference guide / list of recipes to perform common data science tasks in an efficient way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "* [Best practices](#best_practices)\n",
    "* [Compute correlation matrix](#corr_matrix)\n",
    "* [Deal with dates](#dates)\n",
    "* [Deal with NAs](#NAs)\n",
    "* [Deal with constant / quasi-constant variables](#constant_variables)\n",
    "* [Load data from multiple files and concatenate](#load_concat)\n",
    "* [Force Python to reload a module](#module_reload) \n",
    "* [Save a dataframe to .csv](#save_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"best_practices\"></a> Best practices\n",
    "There are often several ways of performing a given task in Python, such as iterating on a list for instance. Below I tried to list some common tasks with the corresponding good / best practice that I found after experiencing and crawling Stackoverflow and co."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## > Iterate on a dictionary\n",
    "The idiomatic way is to use `items()` to iterate accros the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key First Name has value John\n",
      "Key Last Name has value Doe\n"
     ]
    }
   ],
   "source": [
    "d = {'First Name': 'John', 'Last Name': 'Doe'}\n",
    "for key, val in d.items():\n",
    "    print('Key ' + key + ' has value ' + val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## > Iterate on a list and access the index\n",
    "Here the trick is to use `enumerate` rather than creating an index value that we would manually increment. \n",
    "`enumerate` makes things smooth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 a\n",
      "1 b\n",
      "2 c\n"
     ]
    }
   ],
   "source": [
    "items = ['a', 'b', 'c']\n",
    "for index, item in enumerate(items, start=0):   # default is zero\n",
    "    print(index, item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"corr_matrix\"></a> Compute correlation matrix\n",
    "It can be cumbersome to get the list of the most correlated pairs of variables in a data set. Here is an example of how to do so, quite smoothly. \n",
    "\n",
    "* We first create a toy dataset with 20 features and 5 correlated pairs of features to play with\n",
    "* Then, the correlation matrix is computed using the `pandas.DataFrame.corr()` command\n",
    "* To extract the relevant part of the matrix, a boolean mask is created with the `numpy.triu()` command\n",
    "* Finally, the matrix is converted to a Pandas Series with a multi-index using the `pandas.DataFrame.stack()` command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "X, y = make_classification(n_features=10, n_informative=3, n_redundant=5, n_classes=2,\n",
    "    n_clusters_per_class=2)\n",
    "\n",
    "col_names = ['feature_' + str(i) for i in range(X.shape[1])]\n",
    "X = pd.DataFrame(X, columns=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>feature_0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.823849</td>\n",
       "      <td>0.973042</td>\n",
       "      <td>-0.949994</td>\n",
       "      <td>-0.896065</td>\n",
       "      <td>0.764993</td>\n",
       "      <td>-0.160190</td>\n",
       "      <td>0.170617</td>\n",
       "      <td>-0.032467</td>\n",
       "      <td>0.198784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_1</th>\n",
       "      <td>-0.823849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.689932</td>\n",
       "      <td>0.812806</td>\n",
       "      <td>0.625704</td>\n",
       "      <td>-0.975139</td>\n",
       "      <td>0.105197</td>\n",
       "      <td>-0.631158</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>-0.579045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_2</th>\n",
       "      <td>0.973042</td>\n",
       "      <td>-0.689932</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.877041</td>\n",
       "      <td>-0.958594</td>\n",
       "      <td>0.649724</td>\n",
       "      <td>-0.177422</td>\n",
       "      <td>0.051843</td>\n",
       "      <td>-0.046402</td>\n",
       "      <td>-0.028937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_3</th>\n",
       "      <td>-0.949994</td>\n",
       "      <td>0.812806</td>\n",
       "      <td>-0.877041</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.718516</td>\n",
       "      <td>-0.694186</td>\n",
       "      <td>0.118221</td>\n",
       "      <td>-0.063240</td>\n",
       "      <td>0.013887</td>\n",
       "      <td>-0.428114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_4</th>\n",
       "      <td>-0.896065</td>\n",
       "      <td>0.625704</td>\n",
       "      <td>-0.958594</td>\n",
       "      <td>0.718516</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.648473</td>\n",
       "      <td>0.193494</td>\n",
       "      <td>-0.168040</td>\n",
       "      <td>0.057019</td>\n",
       "      <td>0.225775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "feature_0   1.000000  -0.823849   0.973042  -0.949994  -0.896065   0.764993   \n",
       "feature_1  -0.823849   1.000000  -0.689932   0.812806   0.625704  -0.975139   \n",
       "feature_2   0.973042  -0.689932   1.000000  -0.877041  -0.958594   0.649724   \n",
       "feature_3  -0.949994   0.812806  -0.877041   1.000000   0.718516  -0.694186   \n",
       "feature_4  -0.896065   0.625704  -0.958594   0.718516   1.000000  -0.648473   \n",
       "\n",
       "           feature_6  feature_7  feature_8  feature_9  \n",
       "feature_0  -0.160190   0.170617  -0.032467   0.198784  \n",
       "feature_1   0.105197  -0.631158   0.000368  -0.579045  \n",
       "feature_2  -0.177422   0.051843  -0.046402  -0.028937  \n",
       "feature_3   0.118221  -0.063240   0.013887  -0.428114  \n",
       "feature_4   0.193494  -0.168040   0.057019   0.225775  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute correlation matrix\n",
    "cor_matrix = X.corr()\n",
    "cor_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we want to extract the upper-part of the matrix (becauses the correlation matrix is symetrical), to do so we will generate a boolean mask array from an upper triangular matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following mask has been generated: \n",
      "\n",
      "[[False  True  True  True  True  True  True  True  True  True]\n",
      " [False False  True  True  True  True  True  True  True  True]\n",
      " [False False False  True  True  True  True  True  True  True]\n",
      " [False False False False  True  True  True  True  True  True]\n",
      " [False False False False False  True  True  True  True  True]\n",
      " [False False False False False False  True  True  True  True]\n",
      " [False False False False False False False  True  True  True]\n",
      " [False False False False False False False False  True  True]\n",
      " [False False False False False False False False False  True]\n",
      " [False False False False False False False False False False]]\n"
     ]
    }
   ],
   "source": [
    "mask = np.triu(np.ones(cor_matrix.shape), k=1).astype(np.bool)\n",
    "print('The following mask has been generated: \\n')\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When applied to our correlation matrix, it will only keep the upper part, excluding the diagonal. We use `.abs()`at the end because we are interested in variables positively and negatively correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>feature_0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.823849</td>\n",
       "      <td>0.973042</td>\n",
       "      <td>0.949994</td>\n",
       "      <td>0.896065</td>\n",
       "      <td>0.764993</td>\n",
       "      <td>0.160190</td>\n",
       "      <td>0.170617</td>\n",
       "      <td>0.032467</td>\n",
       "      <td>0.198784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.689932</td>\n",
       "      <td>0.812806</td>\n",
       "      <td>0.625704</td>\n",
       "      <td>0.975139</td>\n",
       "      <td>0.105197</td>\n",
       "      <td>0.631158</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.579045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.877041</td>\n",
       "      <td>0.958594</td>\n",
       "      <td>0.649724</td>\n",
       "      <td>0.177422</td>\n",
       "      <td>0.051843</td>\n",
       "      <td>0.046402</td>\n",
       "      <td>0.028937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.718516</td>\n",
       "      <td>0.694186</td>\n",
       "      <td>0.118221</td>\n",
       "      <td>0.063240</td>\n",
       "      <td>0.013887</td>\n",
       "      <td>0.428114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.648473</td>\n",
       "      <td>0.193494</td>\n",
       "      <td>0.168040</td>\n",
       "      <td>0.057019</td>\n",
       "      <td>0.225775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.115363</td>\n",
       "      <td>0.756552</td>\n",
       "      <td>0.006447</td>\n",
       "      <td>0.460539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.034566</td>\n",
       "      <td>0.064570</td>\n",
       "      <td>0.069284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012584</td>\n",
       "      <td>0.361545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.058279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "feature_0        NaN   0.823849   0.973042   0.949994   0.896065   0.764993   \n",
       "feature_1        NaN        NaN   0.689932   0.812806   0.625704   0.975139   \n",
       "feature_2        NaN        NaN        NaN   0.877041   0.958594   0.649724   \n",
       "feature_3        NaN        NaN        NaN        NaN   0.718516   0.694186   \n",
       "feature_4        NaN        NaN        NaN        NaN        NaN   0.648473   \n",
       "feature_5        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "feature_6        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "feature_7        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "feature_8        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "feature_9        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "           feature_6  feature_7  feature_8  feature_9  \n",
       "feature_0   0.160190   0.170617   0.032467   0.198784  \n",
       "feature_1   0.105197   0.631158   0.000368   0.579045  \n",
       "feature_2   0.177422   0.051843   0.046402   0.028937  \n",
       "feature_3   0.118221   0.063240   0.013887   0.428114  \n",
       "feature_4   0.193494   0.168040   0.057019   0.225775  \n",
       "feature_5   0.115363   0.756552   0.006447   0.460539  \n",
       "feature_6        NaN   0.034566   0.064570   0.069284  \n",
       "feature_7        NaN        NaN   0.012584   0.361545  \n",
       "feature_8        NaN        NaN        NaN   0.058279  \n",
       "feature_9        NaN        NaN        NaN        NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper_cor_matrix = cor_matrix.where(mask).abs()\n",
    "upper_cor_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make it easier to use, the columns are stacked into rows, resulting in a multi-index Pandas Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display the most-correlated pairs:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "feature_1  feature_5    0.975139\n",
       "feature_0  feature_2    0.973042\n",
       "feature_2  feature_4    0.958594\n",
       "feature_0  feature_3    0.949994\n",
       "           feature_4    0.896065\n",
       "feature_2  feature_3    0.877041\n",
       "feature_0  feature_1    0.823849\n",
       "feature_1  feature_3    0.812806\n",
       "feature_0  feature_5    0.764993\n",
       "feature_5  feature_7    0.756552\n",
       "feature_3  feature_4    0.718516\n",
       "           feature_5    0.694186\n",
       "feature_1  feature_2    0.689932\n",
       "feature_2  feature_5    0.649724\n",
       "feature_4  feature_5    0.648473\n",
       "feature_1  feature_7    0.631158\n",
       "           feature_4    0.625704\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor_series = upper_cor_matrix.stack().sort_values(ascending=False)\n",
    "print('Display the most-correlated pairs:')\n",
    "cor_series[cor_series > 0.6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deal with constant and quasi-variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"dates\"></a> Deal with dates\n",
    "The common operations involve:\n",
    "\n",
    "* converting a `string` to a `datetime` object or the reverse operation\n",
    "* changing the format of the displayed date, like removing day, month, year information and keep only time information\n",
    "* computing date / time differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## > Parse a `string` into a `datetime` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The created object has the following type: <class 'datetime.datetime'>\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "my_date = datetime.datetime.strptime('2012-07-22 16:19:00.539570', '%Y-%m-%d %H:%M:%S.%f')\n",
    "print('The created object has the following type: %s' % type(my_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## > Parse a `string` into `datetime` object when loading a .csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When loading data from a .csv file, it may be handy to take care of the date column at the same time, rather than modifying thedate column in another command. To do so, one may define a date parser function that will be applied on the date column when reading the csv.\n",
    "\n",
    "To demonstrate this, we generate a fake .csv file with a date column. The date will be written as '15', '16', '17' for 2015, 2016 and 2017 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  date\n",
      "0   15\n",
      "1   16\n",
      "2   17\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import datetime\n",
    "\n",
    "df = pd.DataFrame(['15', '16', '17'], columns = ['date'])\n",
    "print(df.head())\n",
    "\n",
    "# save dataframe\n",
    "df.to_csv('./data/tmp.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now demonstrate how to define a date parser and load the csv properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date\n",
       "0 2015-01-01\n",
       "1 2016-01-01\n",
       "2 2017-01-01"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def date_parser(x):\n",
    "    return datetime.strptime('20' + x, '%Y')\n",
    "\n",
    "pd.read_csv('./data/tmp.csv', parse_dates = [0], date_parser=date_parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## > Format a `datetime` object to a `string`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To format a `datetime` object to a string, the function to use is `strftime()`. The list of date formatters can be found [here](https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output current time as a formatted string:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2018-01-05 11:27:51.252837'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "print('Output current time as a formatted string:')\n",
    "datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name='NAs'></a>Deal with NAs\n",
    "\n",
    "Dealing with missing values may involve:\n",
    "* assessing the dataset to find the rows / columns containing missing values\n",
    "* removing the records containing missing values\n",
    "* filling the missing values with an alternate value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## > Drop NAs using `Pandas.DataFrame.dropna(axis, how, thresh)`\n",
    "\n",
    "Pandas can look for NA column-wise or row-wise, drop a label if any or all values are NA and use a threshold for deletion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## > Spot NAs using `apply()` and a lambda function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lambda function combined with `Pandas.DataFrame.apply()` may be used to spot NAs and then take some action. Things to remember :\n",
    "* if `x`is a DataFrame, then `x.isnull()` returns a boolean same-sized object indicating if the values are NA. \n",
    "* applying either `all()` or `any()` on `x.isnull()` checks if any or all of the value in the DataFrame are NA \n",
    "\n",
    "Let's take ta toy example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    x1  x2  x3\n",
      "0  0.0 NaN   1\n",
      "1  NaN NaN   2\n",
      "\n",
      "The following column(s) contain only NAs:\n",
      "['x2']\n",
      "\n",
      "\n",
      "The following column(s) contain at least one NA\n",
      "['x1' 'x2']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.DataFrame([[0, np.nan, 1], [np.nan, np.nan, 2]], columns = ['x1', 'x2', 'x3'])\n",
    "print(df)\n",
    "\n",
    "# create a boolean mask with columns containing only NAs\n",
    "cols = df.apply(lambda x: all(x.isnull()), axis=0)\n",
    "print('\\nThe following column(s) contain only NAs:')\n",
    "print(df.columns[cols].values)\n",
    "print('\\n')\n",
    "\n",
    "cols = df.apply(lambda x: any(x.isnull()), axis=0)\n",
    "print('The following column(s) contain at least one NA')\n",
    "print(df.columns[cols].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name='module_reload'></a>Force Python to reload a module\n",
    "\n",
    "Once a module has been loaded using `import module_name`, running this same command again will not reload the module. \n",
    "\n",
    "Say you are making changes on a module and testing the result interactively in a python shell. If you have loaded the module once and want to see the new changes you have to use:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{python}\n",
    "import importlib\n",
    "importlib.reload(module_name)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name='load_concat'></a> Load data from multiple files and concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python `glob.glob()` command is used to find all the files in a directory matching a path pattern (**be careful, the files are return in an unsorted order**).\n",
    "\n",
    "`map()` command is applied to the file list to read the csv files via a lambda function.\n",
    "\n",
    "The result is eventually concatenated using `Pandas.concat()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of files found:\n",
      "['./data/file1.csv', './data/file2.csv']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>john doe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>donald trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>bill clinton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>hillary clinton</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id              name\n",
       "0   1          john doe\n",
       "1   2      donald trump\n",
       "0   3      bill clinton\n",
       "1   4   hillary clinton"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "files = glob.glob('./data/file*.csv')\n",
    "print('List of files found:')\n",
    "print(files)\n",
    "df1 = pd.concat(map(lambda file: pd.read_csv(file, sep=','), files))\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name='save_csv'></a>Save a dataframe to .csv file\n",
    "\n",
    "Full documentation on the `Pandas.DataFrame.to_csv()` command may be found here: [official documentation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_csv.html)\n",
    "\n",
    "Ok this one may seem obvious but if you want your `Pandas.DataFrame` to be easily readable afterwards, you have to take care:\n",
    "* if your dataframe doest not have an index, I suggest that you pass `index=False` to `Pandas.DataFrame.to_csv()` so that row numbers are not saved in the .csv file. This will prevent any trouble from occuring when loading the file again\n",
    "* if your dataframe already has an index that you want to keep, the default value `index=True` in `Pandas.DataFrame.to_csv()` will work fine\n",
    "* if you don't have an index yet but want to save the dataframe and use an existing column as the index for future reading, then you can specify `index=True` AND `index_label=my_future_index_column`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
